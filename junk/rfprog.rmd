---
title: "Man vs model: random forest tuning and optimisation"
author: "Luke Hayden"
date: "Oct 1st, 2018"
output: html_document
---



```{r, echo=FALSE, warning=FALSE, error=FALSE, message=FALSE}

#Set-up and data import
library(dplyr)
library(ggbiplot)
library(tibble)
library(tidyr)
library(caret)
library(RColorBrewer)
library(ggrepel)
library(gtools)
library(FinCal)
````


Will start with 61 markers, examine the contribution of each, then make progressive additional models using fewer and fewer markers

```{r, echo=FALSE, warning=FALSE, error=FALSE, message=FALSE}
#setwd("~/Documents/nstringjul18")
load(file="allns_data.rdata")

load(file="sampleinfo.rdata")


#save(cvdf,lmdf, lmdf2,  file="vardat.rdata")
load(file="vardat.rdata")
load(file="models.rdata")

load(file="progmodels.rdata")
load(file="qualitydat.rdata")
load(file="markerchoiceinfo.rdata")

````

###Parameters


ntree: number of trees

mtry: Number of variables randomly sampled as candidates at each split

min.node.size: sets depth of trees

cross-validation folds: number of repartitions of data for testing 

splitting model: variance or "extratrees"

This is how they affect the model, below. Note: lower RMSE is better. 



#Initial model
Using 61 markers



```{r, echo=FALSE, warning=FALSE, error=FALSE, message=FALSE}
#Random forest
md <- as.data.frame(subset(t(ctall.norm), sampleinfo$sex == "F" &
#               sampleinfo$qual == "ok"&
                 sampleinfo$prep== "Luke"&
                 sampleinfo$exp %in% c("Size-age", "cohorts", "OvY") &
 #                sampleinfo$ctg>2 &
                sampleinfo$codeset == "phaw_1" &
                 sampleinfo$type %in% c("O", "Y", "M")
))

md <- subset(md, rownames(md)%in% qualsum$sample[qualsum$good])
md <- md[, lmdf2$in61 ==T]

#md <- md[,colnames(md) %in% currbest$coefnames]



md$sample <- rownames(md)

md <- left_join(md, select(sampleinfo, sample, predage), by="sample") %>%
  filter(!(is.na(predage))) %>%
  column_to_rownames(var="sample")


trainchoice <- sample(1:nrow(md))[1:floor(4*(nrow(md)/5))]


trainchoice <- rownames(md) %in% rownames(currbest$trainingData)
trdat <- md[trainchoice,]
tedat <-   md[!(rownames(md) %in% rownames(trdat)),]



rfagemodel61 <- train(
  predage~.,
  tuneLength = 4,
  metric="RMSE",
  num.trees=2000,
  importance = "permutation",
  data = trdat, method = "ranger",
  tuneGrid=expand.grid(mtry=c(10:20),
                        splitrule=c("extratrees", "variance"),
                        min.node.size=c(1:10)),
  trControl = trainControl(method = "cv", number = 40, verboseIter = T)
)
```



##Model accuracy: age from body length regression





```{r, echo=FALSE, warning=FALSE, error=FALSE, message=FALSE}

mymodel <- rfagemodel61
#mymodel <- currbest


md <- as.data.frame(subset(t(ctall.norm), sampleinfo$sex == "F" &

                 sampleinfo$prep== "Luke"&
                 sampleinfo$exp %in% c("Size-age", "cohorts", "OvY") &
                 sampleinfo$ctg>2 &
                 sampleinfo$type %in% c("O", "Y", "M") 
)
)
md <- md[, lmdf2$in61 ==T]


md <- subset(md, rownames(md)%in% qualsum$sample[qualsum$good])

md <- md[,colnames(md) %in% mymodel$coefnames]



md$rfagepred <- predict(mymodel, newdata=md)


md$intrain <- rownames(md) %in% rownames(mymodel$trainingData)



md <- md %>%
  rownames_to_column(var="sample") %>%
  left_join(sampleinfo,  by="sample")

md <- subset(md, !(is.na(md$predage)))


RMSEtr <- sqrt(mean( (md$rfagepred[md$intrain == T] - md$predage[md$intrain == T])   ^2))
RMSEte <- sqrt(mean( (md$rfagepred[md$intrain == F] - md$predage[md$intrain == F])   ^2))


(p=ggplot(md, aes(x=predage, y=rfagepred,colour=intrain))+
  geom_point()+
  xlab("Age (weeks) from body length") +
  ylab("Age (weeks) from marker gene expression (random forest model)")+
  geom_smooth(method="lm", colour="black")+
  theme_bw()+
 scale_colour_manual(values=c("cornflower blue", "red3"), name="Data partition", labels=c("Test", "Training"))+
  geom_text_repel(aes(label=sample), size=2.5)+
  ggtitle("Using Marker gene expression to predict age", 
          subtitle=paste0(length(mymodel$coefnames), 
            " markers in model \nRMSE in training data: ", round(RMSEtr,3), 
                          "\nRMSE in test data: ", round(RMSEte,3))))#+  facet_wrap(~intrain)


#ggsave(plot=p,height=5,width=6,dpi=200, filename=paste("modeltrte.pdf"), useDingbats=FALSE, limitsize = FALSE)


```




####Variable importance

Variable importance obtained via permutation 

```{r, echo=FALSE, warning=FALSE, error=FALSE, message=FALSE}
mymodel <- rfagemodel61

#mymodel <- currbest

vrimprf <-varImp(mymodel)$importance %>%
  rownames_to_column(var="name")
vrimprf$sname <- substr(vrimprf$name, 1,2)

vrimprf$sname <- factor(vrimprf$sname, levels=vrimprf$sname[order(vrimprf$Overall, decreasing=T)])

vrimprf$pos <- match(vrimprf$sname, levels(vrimprf$sname))
  

cutoffs <- c(55,50,45,40,35,30,25,20,15,10,5)
 

vrimprf$groupin <- 5*ceiling(vrimprf$pos/5)
vrimprf$groupin[vrimprf$groupin %in% c(60, 65)] <- 61
vrimprf$groupin <- as.factor(vrimprf$groupin)

(p=ggplot(vrimprf, aes(x=pos, y=Overall, label=sname, fill=groupin))+
  theme_bw()+
  geom_vline(xintercept=cutoffs+0.5, linetype=2)+
  geom_text(size=2.3, angle=60, y=-3)+
    
  scale_fill_brewer(palette="Set3")+
  geom_bar(stat="identity")+
  theme(axis.text.x = element_text(angle = 60, hjust = 1))+
  xlab("Marker")+
  ylab("Contribution to model")+
  ggtitle("Marker contributions", subtitle= paste0("random forest model built with ", length(mymodel$coefnames), " markers"))
)

save(rfagemodel61, file="progmodels.rdata")
````


```{r, echo=FALSE, warning=FALSE, error=FALSE, message=FALSE}
modellist <- list()



maindata <-  as.data.frame(subset(t(ctall.norm), sampleinfo$sex == "F" &
#               sampleinfo$qual == "ok"&
                 sampleinfo$prep== "Luke"&
                 sampleinfo$exp %in% c("Size-age", "cohorts", "OvY") &
 #                sampleinfo$ctg>2 &
                sampleinfo$codeset == "phaw_1" &
                 sampleinfo$type %in% c("O", "Y", "M")
))


maindata <- subset(maindata, rownames(maindata)%in% qualsum$sample[qualsum$good])

maindata <- maindata[, lmdf2$in61 ==T ]


for (i in 1:length(cutoffs)){
  print(i)

md <- as.data.frame(maindata[, colnames(maindata) %in% vrimprf$name[vrimprf$pos <= cutoffs[i]]])




md$sample <- rownames(md)

md <- left_join(md, select(sampleinfo, sample, predage), by="sample") %>%
  filter(!(is.na(predage))) %>%
  column_to_rownames(var="sample")



trainchoice <- rownames(md) %in% rownames(currbest$trainingData)
trdat <- md[trainchoice,]
tedat <- md[-trainchoice,]



currmodel <- train(
  predage~.,
  tuneLength = 4,
  metric="RMSE",
#  num.trees=2000,
 # importance = "permutation",
  data = trdat, method = "lm"
  #tuneGrid=expand.grid(mtry=c(10:20),
   #                     splitrule=c("extratrees", "variance"),
    #                    min.node.size=c(1:10)),
#  trControl = trainControl(method = "cv", number = 1, verboseIter = T)
)

modellist[[i]] <- currmodel
}






```



##Model accuracy: age from body length regression


```{r, echo=FALSE, warning=FALSE, error=FALSE, message=FALSE}
plotlist <- list()

for (i in 1:length(modellist)){
  
mymodel <- modellist[i]
  
#mymodel <- modellist[1]


md <- as.data.frame(subset(t(ctall.norm), sampleinfo$sex == "F" &
#               sampleinfo$qual == "ok"&
                 sampleinfo$prep== "Luke"&
                 sampleinfo$exp %in% c("Size-age", "cohorts", "OvY") &
 #                sampleinfo$ctg>2 &
                sampleinfo$codeset == "phaw_1" &
                 sampleinfo$type %in% c("O", "Y", "M")
))

md <- subset(md, rownames(md)%in% qualsum$sample[qualsum$good])

md <- md[,colnames(md) %in% mymodel$coefnames]



md$rfagepred <- predict(mymodel, newdata=md)


md$intrain <- rownames(md) %in% rownames(mymodel$trainingData)



md <- md %>%
  rownames_to_column(var="sample") %>%
  left_join(sampleinfo,  by="sample")

md <- subset(md, !(is.na(md$predage)))


RMSEtr <- sqrt(mean( (md$rfagepred[md$intrain == T] - md$predage[md$intrain == T])   ^2))
RMSEte <- sqrt(mean( (md$rfagepred[md$intrain == F] - md$predage[md$intrain == F])   ^2))


plotlist[i]=ggplot(md, aes(x=predage, y=rfagepred,colour=intrain))+
  geom_point()+
  xlab("Age (weeks) from body length") +
  ylab("Age (weeks) from marker gene expression (random forest model)")+
  geom_smooth(method="lm", colour="black")+
  theme_bw()+
 scale_colour_manual(values=c("cornflower blue", "red3"), name="Data partition", labels=c("Test", "Training"))+
  geom_text_repel(aes(label=sample), size=2.5)+
  ggtitle("Using Marker gene expression to predict age", 
          subtitle=paste0(length(mymodel$coefnames), 
            " markers in model \nRMSE in training data: ", round(RMSEtr,3), 
                          "\nRMSE in test data: ", round(RMSEte,3)))
}

multiplot(plotlist=plotlist, cols=2)

```






#Interrogating the model


Markers used:


```{r, echo=FALSE, warning=FALSE, error=FALSE, message=FALSE}

mymodel <- currbest
#mymodel <- rfagemodel

mymodel$coefnames


````

####Variable importance

Variable importance obtained via permutation 

```{r, echo=FALSE, warning=FALSE, error=FALSE, message=FALSE}
mymodel <- rfagemodel61

vrimprf <-varImp(mymodel)$importance %>%
  rownames_to_column(var="name")
vrimprf$sname <- substr(vrimprf$name, 1,2)

vrimprf$sname <- factor(vrimprf$sname, levels=vrimprf$sname[order(vrimprf$Overall, decreasing=T)])

(p=ggplot(vrimprf, aes(x=sname, y=Overall))+
  theme_bw()+
  geom_bar(stat="identity", fill="red3")+
  theme(axis.text.x = element_text(angle = 60, hjust = 1))+
  xlab("Marker")+
  ylab("Contribution to model")+
  ggtitle("Marker contributions", subtitle= paste0("random forest model built with ", length(mymodel$coefnames), " markers"))
)

ggsave(plot=p,height=5,width=5,dpi=200, filename=paste("contribs61.pdf"), useDingbats=FALSE, limitsize = FALSE)
````


One marker is a huge outlier in this respect, contributing more than twice as much as the next most important marker. 

##Marker profiles

I have also graphed the expression of each marker over time. 


```{r, echo=FALSE, warning=FALSE, error=FALSE, message=FALSE, fig.height = 20}


md <- as.data.frame(subset(t(ctall.norm), sampleinfo$sex == "F" &
#               sampleinfo$qual == "ok"& 
                 sampleinfo$prep== "Luke"&
                 sampleinfo$exp %in% c("Size-age", "cohorts", "OvY") & 
 #                sampleinfo$ctg>2 & 
                sampleinfo$codeset == "phaw_1" &
                 sampleinfo$type %in% c("O", "Y", "M")& 
  !(sampleinfo$sample %in% c("T","C", "U", "LFPD", "O1a", "SFPA", "LFIB","LFIA","AF", "Coh8"))))



md <- md[,colnames(md) %in% mymodel$coefnames]
md <- subset(md, rownames(md) %in% sampleinfo$sample[!is.na(sampleinfo$predage)])

md <-  as.data.frame(md/rowMeans(md))

md <- md %>%
  rownames_to_column(var="sample") %>%
  left_join(sampleinfo,  by="sample") %>%
  gather(key=marker, value= exp, mymodel$coefnames)%>%
  left_join(minf, by=c("marker"="name"))%>%
  left_join(select(vrimprf, -sname), by= c("marker"="name"))

md$lab <- paste0(md$sname, ": ", round(md$Overall,3))


md$lab <- factor(md$lab, levels=unique(md$lab[order(md$Overall, decreasing=T)]))

(p=ggplot(md, aes(x=predage, y= exp, colour=dir))+
  geom_smooth()+
  geom_point(size=0.5)+
  theme_bw()+
  facet_wrap(~lab, scales="free", ncol=3)+
  scale_colour_brewer(palette="Set1")+
  xlab("Age (based on body length)")+
  ylab("Normalised expression")+
  theme(legend.direction = 'horizontal', legend.position = 'bottom')+
 
  ggtitle("Marker profiles", subtitle= paste0("markers from random forest model built with ", length(mymodel$coefnames), " markers")) )



ggsave(plot=p,height=18,width=6,dpi=200, filename=paste("contribprofiles61.pdf"), useDingbats=FALSE, limitsize = FALSE)



````

It looks like some optimisation on the basis of these profiles may furhter improve the model's fit. 
